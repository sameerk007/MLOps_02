{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Run, Experiment,Workspace\n",
    "from azureml.data import OutputFileDatasetConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = Workspace.from_config()\n",
    "experiment = Experiment(workspace, 'output_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = OutputFileDatasetConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mOutputFileDatasetConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdestination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpartition_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Represent how to copy the output of a run and be promoted as a FileDataset.\n",
      "\n",
      "The OutputFileDatasetConfig allows you to specify how you want a particular local path on the compute target\n",
      "to be uploaded to the specified destination. If no arguments are passed to the constructor, we will\n",
      "automatically generate a name, a destination, and a local path.\n",
      "\n",
      "An example of not passing any arguments:\n",
      "\n",
      ".. code-block:: python\n",
      "\n",
      "    workspace = Workspace.from_config()\n",
      "    experiment = Experiment(workspace, 'output_example')\n",
      "\n",
      "    output = OutputFileDatasetConfig()\n",
      "\n",
      "    script_run_config = ScriptRunConfig('.', 'train.py', arguments=[output])\n",
      "\n",
      "    run = experiment.submit(script_run_config)\n",
      "    print(run)\n",
      "\n",
      "An example of creating an output then promoting the output to a tabular dataset and register it with\n",
      "name foo:\n",
      "\n",
      ".. code-block:: python\n",
      "\n",
      "    workspace = Workspace.from_config()\n",
      "    experiment = Experiment(workspace, 'output_example')\n",
      "\n",
      "    datastore = Datastore(workspace, 'example_adls_gen2_datastore')\n",
      "\n",
      "    # for more information on the parameters and methods, please look for the corresponding documentation.\n",
      "    output = OutputFileDatasetConfig().read_delimited_files().register_on_complete('foo')\n",
      "\n",
      "    script_run_config = ScriptRunConfig('.', 'train.py', arguments=[output])\n",
      "\n",
      "    run = experiment.submit(script_run_config)\n",
      "    print(run)\n",
      "\n",
      ".. remarks::\n",
      "    You can pass the OutputFileDatasetConfig as an argument to your run, and it will be automatically\n",
      "    translated into local path on the compute. The source argument will be used if one is specified,\n",
      "    otherwise we will automatically generate a directory in the OS's temp folder. The files and folders inside\n",
      "    the source directory will then be copied to the destination based on the output configuration.\n",
      "\n",
      "    By default the mode by which the output will be copied to the destination storage will be set to mount.\n",
      "    For more information about mount mode, please see the documentation for as_mount.\n",
      "\n",
      ":param name: The name of the output specific to this run. This is generally used for lineage purposes. If set\n",
      "    to None, we will automatically generate a name. The name will also become an environment variable which\n",
      "    contains the local path of where you can write your output files and folders to that will be uploaded to\n",
      "    the destination.\n",
      ":type name: str\n",
      ":param destination: The destination to copy the output to. If set to None, we will copy the output to the\n",
      "    workspaceblobstore datastore, under the path /dataset/{run-id}/{output-name}, where `run-id` is the Run's\n",
      "    ID and the `output-name` is the output name from the `name` parameter above. The destination is a tuple\n",
      "    where the first item is the datastore and the second item is the path within the datastore to copy the\n",
      "    data to.\n",
      "\n",
      "    The path within the datastore can be a template path. A template path is just a regular path but with\n",
      "    placeholders inside. Those placeholders will then be resolved at the appropriate time. The syntax for\n",
      "    placeholders is {placeholder}, for example, /path/with/{placeholder}. Currently only two placeholders\n",
      "    are supported, {run-id} and {output-name}.\n",
      ":type destination: tuple\n",
      ":param source: The path within the compute target to copy the data from. If set to None, we\n",
      "    will set this to a directory we create inside the compute target's OS temporary directory.\n",
      ":type source: str\n",
      ":param partition_format: Specify the partition format of path. Defaults to None.\n",
      "        The partition information of each path will be extracted into columns based on the specified format.\n",
      "        Format part '{column_name}' creates string column, and '{column_name:yyyy/MM/dd/HH/mm/ss}' creates\n",
      "        datetime column, where 'yyyy', 'MM', 'dd', 'HH', 'mm' and 'ss' are used to extract year, month, day,\n",
      "        hour, minute and second for the datetime type. The format should start from the position of first\n",
      "        partition key until the end of file path.\n",
      "        For example, given the path '../Accounts/2019/01/01/data.parquet' where the partition is by\n",
      "        department name and time, partition_format='/{Department}/{PartitionDate:yyyy/MM/dd}/data.parquet'\n",
      "        creates a string column 'Department' with the value 'Accounts' and a datetime column 'PartitionDate'\n",
      "        with the value '2019-01-01'.\n",
      ":type partition_format: str\n",
      "\u001b[0;31mInit docstring:\u001b[0m\n",
      "Initialize a OutputFileDatasetConfig.\n",
      "\n",
      "The OutputFileDatasetConfig allows you to specify how you want a particular local path on the compute target\n",
      "to be uploaded to the specified destination. If no arguments are passed to the constructor, we will\n",
      "automatically generate a name, a destination, and a local path.\n",
      "\n",
      "An example of not passing any arguments:\n",
      "\n",
      ".. code-block:: python\n",
      "\n",
      "    workspace = Workspace.from_config()\n",
      "    experiment = Experiment(workspace, 'output_example')\n",
      "\n",
      "    output = OutputFileDatasetConfig()\n",
      "\n",
      "    script_run_config = ScriptRunConfig('.', 'train.py', arguments=[output])\n",
      "\n",
      "    run = experiment.submit(script_run_config)\n",
      "    print(run)\n",
      "\n",
      "An example of creating an output then promoting the output to a tabular dataset and register it with\n",
      "name foo:\n",
      "\n",
      ".. code-block:: python\n",
      "\n",
      "    workspace = Workspace.from_config()\n",
      "    experiment = Experiment(workspace, 'output_example')\n",
      "\n",
      "    datastore = Datastore(workspace, 'example_adls_gen2_datastore')\n",
      "\n",
      "    # for more information on the parameters and methods, please look for the corresponding documentation.\n",
      "    output = OutputFileDatasetConfig().read_delimited_files().register_on_complete('foo')\n",
      "\n",
      "    script_run_config = ScriptRunConfig('.', 'train.py', arguments=[output])\n",
      "\n",
      "    run = experiment.submit(script_run_config)\n",
      "    print(run)\n",
      "\n",
      ".. remarks::\n",
      "    You can pass the OutputFileDatasetConfig as an argument to your run, and it will be automatically\n",
      "    translated into local path on the compute. The source argument will be used if one is specified,\n",
      "    otherwise we will automatically generate a directory in the OS's temp folder. The files and folders inside\n",
      "    the source directory will then be copied to the destination based on the output configuration.\n",
      "\n",
      "    By default the mode by which the output will be copied to the destination storage will be set to mount.\n",
      "    For more information about mount mode, please see the documentation for as_mount.\n",
      "\n",
      ":param name: The name of the output specific to this run. This is generally used for lineage purposes. If set\n",
      "    to None, we will automatically generate a name. The name will also become an environment variable which\n",
      "    contains the local path of where you can write your output files and folders to that will be uploaded to\n",
      "    the destination.\n",
      ":type name: str\n",
      ":param destination: The destination to copy the output to. If set to None, we will copy the output to the\n",
      "    workspaceblobstore datastore, under the path /dataset/{run-id}/{output-name}, where `run-id` is the Run's\n",
      "    ID and the `output-name` is the output name from the `name` parameter above. The destination is a tuple\n",
      "    where the first item is the datastore and the second item is the path within the datastore to copy the\n",
      "    data to.\n",
      "\n",
      "    The path within the datastore can be a template path. A template path is just a regular path but with\n",
      "    placeholders inside. Those placeholders will then be resolved at the appropriate time. The syntax for\n",
      "    placeholders is {placeholder}, for example, /path/with/{placeholder}. Currently only two placeholders\n",
      "    are supported, {run-id} and {output-name}.\n",
      ":type destination: tuple\n",
      ":param source: The path within the compute target to copy the data from. If set to None, we\n",
      "    will set this to a directory we create inside the compute target's OS temporary directory.\n",
      ":type source: str\n",
      ":param partition_format: Specify the partition format of path. Defaults to None.\n",
      "    The partition information of each path will be extracted into columns based on the specified format.\n",
      "    Format part '{column_name}' creates string column, and '{column_name:yyyy/MM/dd/HH/mm/ss}' creates\n",
      "    datetime column, where 'yyyy', 'MM', 'dd', 'HH', 'mm' and 'ss' are used to extract year, month, day,\n",
      "    hour, minute and second for the datetime type. The format should start from the position of first\n",
      "    partition key until the end of file path.\n",
      "    For example, given the path '../Accounts/2019/01/01/data.parquet' where the partition is by\n",
      "    department name and time, partition_format='/{Department}/{PartitionDate:yyyy/MM/dd}/data.parquet'\n",
      "    creates a string column 'Department' with the value 'Accounts' and a datetime column 'PartitionDate'\n",
      "    with the value '2019-01-01'.\n",
      ":type partition_format: str\n",
      "\u001b[0;31mFile:\u001b[0m           ~/projects/MLOps_02/.venv/lib/python3.8/site-packages/azureml/data/output_dataset_config.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?OutputFileDatasetConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhola\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_on_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "output.as_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azureml.data.output_dataset_config.OutputFileDatasetConfig object at 0x7f95fd73b850>\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "datastore = Datastore(workspace, 'example_adls_gen2_datastore')\n",
    "\n",
    "# for more information on the parameters and methods, please look for the corresponding documentation.\n",
    "output = OutputFileDatasetConfig().read_delimited_files().register_on_complete('foo')\n",
    "\n",
    "script_run_config = ScriptRunConfig('.', 'train.py', arguments=[output])\n",
    "\n",
    "run = experiment.submit(script_run_config)\n",
    "print(run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
